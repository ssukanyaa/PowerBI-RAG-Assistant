{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIZDrWL9RKNA"
      },
      "source": [
        "<center><p float=\"center\">\n",
        "  <img src=\"https://mma.prnewswire.com/media/1458111/Great_Learning_Logo.jpg?p=facebook\" width=\"200\" height=\"100\"/>\n",
        "</p></center>                                                                         <center><h1></h1></center>\n",
        "<h1><left> <font size=5>Project</font></left></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOOFZRO7uQRq"
      },
      "source": [
        "# Business Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfncLsVYbos9"
      },
      "source": [
        "## Implementing a RAG System for Power BI Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGVgYQzanZEq"
      },
      "source": [
        "**Problem Scenario:**\n",
        "\n",
        "In the current data-driven landscape, organizations increasingly rely on powerful analytics tools like Power BI to derive insights and make informed decisions. However, many analysts struggle with the complexity and breadth of Power BI’s official documentation. The extensive resources often lead to confusion, causing users to misinterpret features or overlook essential functionalities. This challenge can result in inefficient data analysis, wasted time, and missed opportunities for actionable insights. Consequently, analysts may not fully leverage the capabilities of Power BI, stifling potential business growth and impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9Gg2LaXuSFT"
      },
      "source": [
        "# Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWbIV8_1ugjj"
      },
      "source": [
        "To address these challenges, we propose implementing a **Retrieval-Augmented Generation (RAG) system** specifically designed for Power BI. This system will enable analysts to formulate questions using natural language and retrieve concise, relevant answers directly from the official documentation. By facilitating better access to critical information, we aim to enhance the operational efficiency of analysts and empower them to utilize Power BI to its fullest potential.\n",
        "\n",
        "The RAG application will simplify interactions with Power BI documentation, allowing users to inquire about specific features, functions, or best practices and receive clear explanations in real-time. By improving understanding and accessibility to the tool, analysts will be able to make quicker, data-driven decisions that lead to a significant business impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbaMSfXqr0Yr"
      },
      "source": [
        "# **<font color=blue> Setting up OpenAI API Key**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "4NkpmCWgt0oH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN9zL8V4t8jv",
        "outputId": "761fcc80-fb5f-43e9-d5d5-24a78c4105d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0FYFyHAuVEs"
      },
      "source": [
        "# Installing and Importing the Necessary Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvZNmXg_yhYK"
      },
      "source": [
        "In this section, we need to install and import libraries required to run the notebook:\n",
        "\n",
        "- The `openai` package provides the official OpenAI API client for accessing models like GPT-4, Whisper, DALL·E, including its embedding models\n",
        "\n",
        "- The `tiktoken`\tlibrary provides access to OpenAI's tokenizer models, crucial for chunking and token counting\n",
        "\n",
        "- The `pypdf` library parses and extracts text from PDF files — useful for document ingestion\n",
        "\n",
        "- LangChain is a GenAI framework to build applications with LLMs using chains and agents.\n",
        "  - `langchain` is the core library that provides access to various LangChain abstractions\n",
        "  - `langchain-community` provides access to 3rd-party integrations (e.g., different vector stores, tools)\n",
        "  - `langchain-chroma` provides specific integration to use ChromaDB as the vector store backend in LangChain\n",
        "  - `langchain-openai` module provides a plug-in interface for LangChain to call OpenAI's LLMs using standardized interface\n",
        "\n",
        "- `chromadb` library provides access to ChromaDB vector database, which is a fast, vector database optimized for retrieval in RAG systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P2VjQSnIe0Oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1aed7be-99a0-408a-9bf8-1588dbffe3ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.4/567.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Installing the required libraries\n",
        "# Installing the required libraries\n",
        "!pip install -q openai==1.66.3 \\\n",
        "                tiktoken==0.9.0 \\\n",
        "                pypdf==5.4.0 \\\n",
        "                langchain==0.3.20 \\\n",
        "                langchain-community==0.3.19 \\\n",
        "                langchain-chroma==0.2.2 \\\n",
        "                langchain-openai==0.3.9 \\\n",
        "                chromadb==0.6.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCQIO2AiukBJ"
      },
      "source": [
        "**Importing the Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LwbwwPJQ9qXf"
      },
      "outputs": [],
      "source": [
        "# Importing the standard Libraries\n",
        "import time                           # For measuring execution time or adding delays\n",
        "from datetime import datetime         # For handling timestamps and datetime operations\n",
        "\n",
        "# ChromaDB Vector Database\n",
        "import chromadb  # Chroma: a local-first vector database for storing and querying document embeddings\n",
        "\n",
        "# OpenAI SDK\n",
        "from openai import OpenAI             # Official OpenAI Python SDK (v1.x) for interacting with models like GPT-4\n",
        "\n",
        "# LangChain Utilities\n",
        "# RecursiveCharacterTextSplitter intelligently breaks long text into smaller chunks with some overlap, preserving context.\n",
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Loads all PDF files from a directory and extracts text from each.\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# Base class representing a document in LangChain; useful for downstream chaining and processing.\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Embeddings and Vector Store\n",
        "# Generates vector embeddings using OpenAI’s embedding models (e.g., `text-embedding-3-small`)\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Integration for using Chroma as the vector store within LangChain’s ecosystem\n",
        "from langchain_chroma import Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup the API Key\n",
        "#### Setup the OpenAI API key and initialize the client with the required model."
      ],
      "metadata": {
        "id": "8V6F2smbQZD9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n7GjHml9hGtD"
      },
      "outputs": [],
      "source": [
        "# Accessing environment variables via Colab Secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set the OpenAI key in Colab Secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY') # Replace with the appropriate secret key name\n",
        "\n",
        "# Refer to the content page present at the top of module for accessing the Open AI API_KEY from Olympus platform\n",
        "# The following code sets up the OpenAI client instance with the API Key and the API Endpoint\n",
        "client = OpenAI(\n",
        "    api_key = openai_api_key,\n",
        "    base_url = \"openai_base_url\" # OpenAI Endpoint Base URL\n",
        ")\n",
        "\n",
        "# GPT-4o-mini will be the primary model used in this notebook\n",
        "model_name = 'gpt-4o-mini'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Vq2MLqv82j"
      },
      "source": [
        "## Creating Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9Ij5gQ6cEljQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ecc00e-b707-4d8c-fec7-02285aca3a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /PowerBI.zip\n",
            "  inflating: Introducing_Power_BI.pdf  \n"
          ]
        }
      ],
      "source": [
        "# Unzip the dataset containing the policy document\n",
        "!unzip /PowerBI.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load PDF Documents and perform chunking\n"
      ],
      "metadata": {
        "id": "8RTgOd3CQ1i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory where PDF files to be stored\n",
        "\n",
        "pdf_folder_location = \"/content/Introducing_Power_BI.pdf\"\n",
        "pdf_loader = PyPDFLoader(pdf_folder_location)\n"
      ],
      "metadata": {
        "id": "-7aDdN-MTGWD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = pdf_loader.load()\n",
        "first_page_text = docs[1].page_content\n",
        "print(first_page_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW4IqYRJ2ZU-",
        "outputId": "f9a3277d-32ac-46a7-e2f5-56dafd70c57c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PUBLISHED BY \n",
            "Microsoft Press \n",
            "A division of Microsoft Corporation \n",
            "One Microsoft Way \n",
            "Redmond, Washington 98052-6399 \n",
            "Copyright © 2016 by Microsoft Corporation \n",
            "All rights reserved. No part of the contents of \n",
            "this book may be reproduced or transmitted in \n",
            "any form or by any means without the written \n",
            "permission of the publisher. \n",
            "ISBN: 978-1-5093-0228-4 \n",
            "Microsoft Press books are available through \n",
            "booksellers and distributors worldwide. If you \n",
            "need support related to this book, email \n",
            "Microsoft Press Support at \n",
            "mspinput@microsoft.com. Please tell us what \n",
            "you think of this book at http://aka.ms/tellpress. \n",
            "This book is provided “as-is” and expresses the \n",
            "author’s views and opinions. The views, opinions \n",
            "and information expressed in this book, \n",
            "including URL and other Internet website \n",
            "references, may change without notice. \n",
            "Some examples depicted herein are provided for \n",
            "illustration only and are fictitious. No real\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunks are stored within LangChain's Document class\n",
        "#enc = tiktoken.encoding_for_model(model_name)\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name= \"cl100k_base\",\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=16\n",
        ")\n",
        "\n",
        "powerbi_chunks = pdf_loader.load_and_split(text_splitter)"
      ],
      "metadata": {
        "id": "aORQ_KJ8W1LQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd1Dow-T_VbJ",
        "outputId": "61250f57-0a69-4a1d-b0b0-4b2a24ab44d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Encoding 'o200k_base'>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "powerbi_chunks[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DrBzRt0yARqj",
        "outputId": "75e9c2a8-3598-4cc6-e29d-5a238b843015"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Introducing\\nMicrosoft \\nPower BI\\nAlberto Ferrari and Marco Russo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(powerbi_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HInEs5u8A6LK",
        "outputId": "b154f22a-5e34-4106-f305-b7c937a542ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "407"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the ChromaDB collection name to store the chunks\n",
        "collection_name = \"powerbi_docs\""
      ],
      "metadata": {
        "id": "FMIxZFh4W-ri"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYo_sC3IMRS3"
      },
      "source": [
        "### Initialize the OpenAI embedding model with the API key, endpoint, and embedding model name.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(\n",
        "    api_key = openai_api_key,\n",
        "    base_url = \"openai_base_url\",\n",
        "    model=\"text-embedding-3-small\"\n",
        ")"
      ],
      "metadata": {
        "id": "dhagetmNdvvT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a persistent Chroma client\n",
        "chromadb_client = chromadb.PersistentClient(\n",
        "    path=\"./powerbi_docs\")\n"
      ],
      "metadata": {
        "id": "2-mbBlDxXDaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ba8037-c5c4-4418-9585-1f17e8208c71"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromadb_client.heartbeat()"
      ],
      "metadata": {
        "id": "BV1frfdyXIja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62d53e8-6530-4f79-fd6c-41af4b12d886"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1761170367830208873"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chromadb_client.count_collections()"
      ],
      "metadata": {
        "id": "d29Eyi_BXMXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a1181e-2bc5-42fb-8911-53e639d24071"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a Chroma vector store to store and retrieve document embeddings\n",
        "vectorstore = Chroma(\n",
        "    client=chromadb_client,\n",
        "    collection_name=collection_name,\n",
        "    collection_metadata = {\"hnsw:space\": \"cosine\"},\n",
        "    embedding_function = embeddings,\n",
        "    persist_directory = \"./powerbi_docs\"\n",
        ")"
      ],
      "metadata": {
        "id": "gVUlGTxaXUgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64364d3-6348-47d1-9d2e-8b7a6a25b420"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# confirm collection creation\n",
        "chromadb_client.list_collections()"
      ],
      "metadata": {
        "id": "uAFBJroEXXjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50377334-6b5d-49a8-a857-2c38c0e20c9e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['powerbi_docs']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lQj6D2SjPVhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7116258-254f-4a28-c391-fa2d298bbb45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Confirm database has been populated with the collection\n",
        "chromadb_client.count_collections()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch 500 chunks to send to the API at a time, pausing execution for 30 seconds afterward\n",
        "batch_size = 500\n",
        "for i in range(0, len(powerbi_chunks), batch_size):\n",
        "    batch = powerbi_chunks[i:i+batch_size]\n",
        "    batch_ids = [f\"text_{idx}\" for idx in range(i, i + len(batch))]\n",
        "    vectorstore.add_documents(batch, ids = batch_ids)\n",
        "    print(f\"Processed batch {i//batch_size + 1}, pausing for 30 seconds...\")\n",
        "    time.sleep(30)"
      ],
      "metadata": {
        "id": "BaSUY_DGX1lZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a1b244-e79a-4034-a801-03e3b8114c7a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1, pausing for 30 seconds...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSyMThOCv3tu"
      },
      "source": [
        "# CRUD Operations in ChromaDB\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBq1KyS3HrwX"
      },
      "source": [
        "## **READ**\n",
        "\n",
        "Once the database is created, the stored entries can be retrieved by initializing a new Chroma instance (denoted as **vectorstore_persisted** to distinguish between creation and read operations) and directing it to the persistent storage directory containing the document embeddings.\n",
        "\n",
        "In this step, you need to:\n",
        "\n",
        "Initialize a new Chroma instance (e.g., vectorstore_persisted) and point it to the persistent storage directory where embeddings are stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UB-G-lAENQrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d47c7d-9fa6-4d13-cd6a-bd365ea879be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ],
      "source": [
        "vectorstore_persisted = Chroma(\n",
        "    collection_name = collection_name,\n",
        "    collection_metadata = {\"hnsw:space\": \"cosine\"},\n",
        "    embedding_function = embeddings,\n",
        "    client = chromadb_client,\n",
        "    persist_directory = \"./powerbi_docs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJB9N2-YdpBH"
      },
      "source": [
        "There are two valuable types of READ operations in vector databases:\n",
        "\n",
        "1. **Inspecting individual records**\n",
        "2. **Retrieving relevant records based on a user query**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr2N7BmFNdLC"
      },
      "source": [
        "**Inspecting individual records**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "awinepx4NYK_"
      },
      "outputs": [],
      "source": [
        "# Define the chroma collection\n",
        "individual_records = chromadb_client.get_collection(collection_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bP4wyfJ1NieH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b8e802-ee82-4479-d2b0-c2694b6e5383"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "407"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Count the number of records in the collection\n",
        "individual_records.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c5dj8sAWNm4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e77eb3c-9a73-4ec3-b7da-74e051f25333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['text_0', 'text_1', 'text_2'],\n",
              " 'embeddings': array([[-0.0141233 , -0.03104495,  0.0387464 , ..., -0.00077508,\n",
              "          0.00032513,  0.01716083],\n",
              "        [ 0.0097238 ,  0.00484162,  0.02150327, ..., -0.019948  ,\n",
              "         -0.01871731,  0.01614773],\n",
              "        [-0.01451573, -0.00566878,  0.01017629, ..., -0.00789198,\n",
              "         -0.00434708,  0.00459538]]),\n",
              " 'documents': ['Introducing\\nMicrosoft \\nPower BI\\nAlberto Ferrari and Marco Russo',\n",
              "  'PUBLISHED BY \\nMicrosoft Press \\nA division of Microsoft Corporation \\nOne Microsoft Way \\nRedmond, Washington 98052-6399 \\nCopyright © 2016 by Microsoft Corporation \\nAll rights reserved. No part of the contents of \\nthis book may be reproduced or transmitted in \\nany form or by any means without the written \\npermission of the publisher. \\nISBN: 978-1-5093-0228-4 \\nMicrosoft Press books are available through \\nbooksellers and distributors worldwide. If you \\nneed support related to this book, email \\nMicrosoft Press Support at \\nmspinput@microsoft.com. Please tell us what \\nyou think of this book at http://aka.ms/tellpress. \\nThis book is provided “as-is” and expresses the \\nauthor’s views and opinions. The views, opinions \\nand information expressed in this book, \\nincluding URL and other Internet website \\nreferences, may change without notice. \\nSome examples depicted herein are provided for \\nillustration only and are fictitious. No real',\n",
              "  'association or connection is intended or should \\nbe inferred. \\nMicrosoft and the trademarks listed at \\nhttp://www.microsoft.com on the “Trademarks” \\nwebpage are trademarks of the Microsoft group \\nof companies. All other marks are property of \\ntheir respective owners. \\nAcquisitions and Developmental Editor: \\nRosemary Caperton \\nEditorial Production: Dianne Russell, Octal \\nPublishing, Inc. \\nCopyeditor: Bob Russell, Octal Publishing, Inc. \\nTechnical Reviewer: Ed Price; Technical Review \\nservices provided by Content Master, a member \\nof CM Group, Ltd. \\nCover: Twist Creative • Seattle'],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'metadatas': [{'author': 'Joan',\n",
              "   'creationdate': '2016-06-13T10:18:21-04:00',\n",
              "   'creator': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'moddate': '2016-06-13T21:13:38-04:00',\n",
              "   'page': 0,\n",
              "   'page_label': '1',\n",
              "   'producer': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'source': '/content/Introducing_Power_BI.pdf',\n",
              "   'title': '',\n",
              "   'total_pages': 407},\n",
              "  {'author': 'Joan',\n",
              "   'creationdate': '2016-06-13T10:18:21-04:00',\n",
              "   'creator': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'moddate': '2016-06-13T21:13:38-04:00',\n",
              "   'page': 1,\n",
              "   'page_label': '2',\n",
              "   'producer': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'source': '/content/Introducing_Power_BI.pdf',\n",
              "   'title': '',\n",
              "   'total_pages': 407},\n",
              "  {'author': 'Joan',\n",
              "   'creationdate': '2016-06-13T10:18:21-04:00',\n",
              "   'creator': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'moddate': '2016-06-13T21:13:38-04:00',\n",
              "   'page': 2,\n",
              "   'page_label': '3',\n",
              "   'producer': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'source': '/content/Introducing_Power_BI.pdf',\n",
              "   'title': '',\n",
              "   'total_pages': 407}],\n",
              " 'included': [<IncludeEnum.embeddings: 'embeddings'>,\n",
              "  <IncludeEnum.documents: 'documents'>,\n",
              "  <IncludeEnum.metadatas: 'metadatas'>]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Inspect the first 3 records using the .peek() method\n",
        "individual_records.peek(3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "individual_records.get(\n",
        "    ids = ['text_50']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyGk8MkGCE_1",
        "outputId": "beeb6a8d-7f2a-47e3-bcfe-8aa695116f98"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': ['text_50'],\n",
              " 'embeddings': None,\n",
              " 'documents': ['33 C H A P T E R  1  |  Introducing Power BI \\n \\nfilter is activated by simply clicking the chart. So \\nfar, you have seen that a filter—when applied to \\nother charts—highlights the relative contribution \\nof the filtered item against the grand total by \\nusing two colors. This behavior is known as \\nvisual interaction, and it is extremely interesting. \\nYet, there are scenarios, like the one David is \\nexperimenting with, for which it would be better \\nto compare the differences between \\ncountries/regions more than the overall \\ncontribution of a brand against the other brands. \\nYou can configure visual interactions in a highly \\nprecise way. Namely, you can configure how the \\nfiltering on a chart behaves with respect to all of \\nthe other ones. The scenario we are looking at—\\nwith only two charts—\\nis perfect for \\nexperimenting because it is very simple. To \\nconfigure visual interactions, on the top menu \\nbar of the report, click the Visual Interactions \\nbutton, which you can see highlighted on the \\nright in Figure 1-23.'],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'metadatas': [{'author': 'Joan',\n",
              "   'creationdate': '2016-06-13T10:18:21-04:00',\n",
              "   'creator': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'moddate': '2016-06-13T21:13:38-04:00',\n",
              "   'page': 50,\n",
              "   'page_label': '51',\n",
              "   'producer': 'Adobe Acrobat Pro 10.1.16',\n",
              "   'source': '/content/Introducing_Power_BI.pdf',\n",
              "   'title': '',\n",
              "   'total_pages': 407}],\n",
              " 'included': [<IncludeEnum.documents: 'documents'>,\n",
              "  <IncludeEnum.metadatas: 'metadatas'>]}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuvUCAL0N2_3"
      },
      "source": [
        "**Retrieving relevant records based on a user query**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws9P7kcod9dE"
      },
      "source": [
        "The primary function of the vector database is to retrieve relevant records based on user queries and to facilitate this process, we implement a retriever that utilizes the query embeddings to query the database.\n",
        "\n",
        "Write code that uses HNSW algorithm to calculate the nearest neighbors for the user query and returns the corresponding documents from the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SUXjsv_wN_R8"
      },
      "outputs": [],
      "source": [
        "# Create a retriever interface from the vector store\n",
        "retriever = vectorstore_persisted.as_retriever(\n",
        "    search_type = 'similarity',             # Use the default method based on semantic similarity\n",
        "    search_kwargs = {'k': 5}                # Retrieve top 5 most similar chunks\n",
        ")\n",
        "\n",
        "# Define a sample user query\n",
        "user_query = \"Give introduction to PowerBi\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWgZ01rWc-51"
      },
      "source": [
        "Write code to  performs the similarity search based on the user query by using the `.invoke()` method."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swNbjkxhDcE_",
        "outputId": "2ce3434b-9957-441d-e645-df6d8387aae4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='text_29', metadata={'author': 'Joan', 'creationdate': '2016-06-13T10:18:21-04:00', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2016-06-13T21:13:38-04:00', 'page': 29, 'page_label': '30', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': '/content/Introducing_Power_BI.pdf', 'title': '', 'total_pages': 407}, page_content='12 C H A P T E R  1  |  Introducing Power BI \\n \\nBefore going any further, we want to take a few \\nmoments to explain how the Power BI portal is \\norganized. On the left side of the screen, in the \\npane labeled My Workspace, there are several \\nitems. Let’s take a look at them: \\n\\uf0b7 Dashboards This lists all of the dashboards \\nyou have created. After loading a single \\nworkbook, Power BI creates a dashboard for \\nyou, using the same name as that of the \\noriginal workbook. \\n\\uf0b7 Reports Here, you will see the reports \\nbased on your data. In Figure 1-7, there is no \\ndefault report, but we’ll follow along as \\nDavid creates one very soon. \\n\\uf0b7 Datasets This lists all of the data sources \\nthat you connected to Power BI. In our \\nnarrative thus far, the only workbook David \\nloaded is 2015 Sales. \\nThe Power BI experience is all about gaining \\ninsights from data. You begin with a dataset \\n(2015 Sales, in this example), you then build \\nreports on the data, and, finally, you organize \\nvisualizations of the reports into dashboards. \\nYou will learn how to perform all of these \\noperations in detail in this book. For the \\nmoment, we want only for you to become \\nacquainted with the basic operations.'),\n",
              " Document(id='text_23', metadata={'author': 'Joan', 'creationdate': '2016-06-13T10:18:21-04:00', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2016-06-13T21:13:38-04:00', 'page': 23, 'page_label': '24', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': '/content/Introducing_Power_BI.pdf', 'title': '', 'total_pages': 407}, page_content='6 C H A P T E R  1  |  Introducing Power BI \\n \\nFortunately, David heard about an interesting \\ntool called Power BI that Microsoft created in \\n2015 that might be helpful toward creating a \\ncollaborative environment in which any \\nstakeholder of the budgeting process can share \\nhis findings with others, working together on the \\ngoal. But, at this point, the name and maybe a \\nmarketing video is all that David knows about \\nPower BI. \\nDriven by curiosity, he navigates to \\nwww.powerbi.com\\n and starts down his learning \\npath. Figure 1-2 depicts the welcome page of \\nthe Power BI website. \\n \\nFigure 1-2: The welcome page of Power BI, the \\nstarting point of David’s journey. \\nTo begin, David clicks the Get Started Free \\nbutton. He is then offered a choice as to which'),\n",
              " Document(id='text_0', metadata={'author': 'Joan', 'creationdate': '2016-06-13T10:18:21-04:00', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2016-06-13T21:13:38-04:00', 'page': 0, 'page_label': '1', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': '/content/Introducing_Power_BI.pdf', 'title': '', 'total_pages': 407}, page_content='Introducing\\nMicrosoft \\nPower BI\\nAlberto Ferrari and Marco Russo'),\n",
              " Document(id='text_72', metadata={'author': 'Joan', 'creationdate': '2016-06-13T10:18:21-04:00', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2016-06-13T21:13:38-04:00', 'page': 72, 'page_label': '73', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': '/content/Introducing_Power_BI.pdf', 'title': '', 'total_pages': 407}, page_content='55 C H A P T E R  1  |  Introducing Power BI \\n \\nthis reason, if you prepare a report that, for \\nexample, filters only 2015, it is always useful to \\nadd a description of the filter as part of the \\nreport title—\\n“Sales in 2015” instead of “Sales.” \\nConclusions \\nAfter this first tour in Power BI, it’s now time to \\ntake a breath and describe what we’ve learned \\nso far. \\n\\uf0b7 Power BI is a cloud service that provides \\ntools to perform analysis of data and gain \\ninsights from your numbers. \\n\\uf0b7 To build a dashboard, you need a dataset, a \\nreport, and, finally, the dashboard. The \\ndataset is the source of data, reports are \\nuseful to create visualizations that might be \\nconnected through visual interactions, and a \\ndashboard is a collection of visualizations \\nand/or reports. \\n\\uf0b7 You can create visualizations by using \\nnatural-language queries, Quick Insights, or \\nfull reports. \\n\\uf0b7 You can decorate a report by using text \\nboxes, shapes, and pictures.'),\n",
              " Document(id='text_11', metadata={'author': 'Joan', 'creationdate': '2016-06-13T10:18:21-04:00', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2016-06-13T21:13:38-04:00', 'page': 11, 'page_label': '12', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': '/content/Introducing_Power_BI.pdf', 'title': '', 'total_pages': 407}, page_content='ix Introduction \\n \\nexperience that was still not completely \\nsatisfactory. While we were waiting for Microsoft \\nto fix the issues with the previous versions and to \\nbegin advertising the current products, it was \\ndoing something different that, with the benefit \\nof hindsight, looks to have been the perfect \\nchoice. Microsoft collected the feedback of \\nusers, carefully considered what was missing in \\nthe world of end-user BI, and then crafted the \\nversion of Power BI that’s available to you today. \\nPower BI is an evolution of the add-ins \\npreviously available in Excel: Power Pivot, Power \\nQuery, and Power View. You can use Power BI \\nwith or without Excel—\\nyou no longer are \\ndependent on the version of Microsoft Office \\ninstalled at your company. People did not like to \\nshare reports by using only SharePoint, and \\nMicrosoft moved away from it. Users wanted a \\nmobile experience, and the development team \\ncreated it. Data analysts wanted power, \\nsimplicity, new visualizations, and all of this is \\nnow available in Power BI. In addition, a lot of \\neffort went into the creation of a seamless \\nexperience in loading data from many different \\ncloud sources and building the infrastructure \\nneeded to provide all BI enthusiasts with a \\nframework with which they can grow their \\nreports, share them with their teams, and refresh \\nthe data in a simple yet effective way.')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations / Learnings\n",
        "* Uniziped filed using PyPDFLoader and not PyPDFDirectoryLoader since we had only one file in the zipped folder.\n",
        "* Verfied the chunks using .page_content\n",
        "* Tried using enc = tiktoken.encoding_for_model(model_name) in text_splitter, but it is choosing o200k_base encoding. So hardcoded it to standard cl100k_base encoding.\n",
        "* Split text with chunk size = 512 and overlap = 16. It basically took one page for each chunk.I don't see any overlap between the chunks because overlap does not work for different pages. If we have 2 chunks from the same page, we would be able to see the overlap.\n",
        "* We need to upload the zip file everytime when the notebook disconnects to the terminal.\n",
        "* Learned to provide stable IDs (text_{i}) to avoid duplicates. It was difficult to do .peek() without stable IDs because it generated random IDs and to verify with the documnet was difficult.\n",
        "* Since we are using k = 5 in retriever, top 5 relevant chunks are returned."
      ],
      "metadata": {
        "id": "3Y9032RZq4yR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgEW08VSOkeT"
      },
      "source": [
        "# RAG Q&A System for PowerBI Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bguX4PvpHekJ"
      },
      "source": [
        "A typical RAG implementation consists of the following stages:\n",
        "* Indexing Stage\n",
        "* Retrieval Stage\n",
        "* Generation Stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd5GR4B3H1zE"
      },
      "source": [
        "| Stage          | Key Activities                                        | Role in RAG                              |\n",
        "| -------------- | ----------------------------------------------------- | ---------------------------------------- |\n",
        "| **Indexing**   | Chunking · Embedding · Storing                        | Prepares data for efficient retrieval    |\n",
        "| **Retrieval**  | Query embedding · Similarity search   | Consolidates relevant context            |\n",
        "| **Generation** | Prompt construction · LLM generation | Produces final response grounded in data |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4qDCb5GH4Jy"
      },
      "source": [
        "Let's now put together the RAG pipeline using these stages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhyBa2NjcbHe"
      },
      "source": [
        "## Retrieval Stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BllDU_R8Er17"
      },
      "source": [
        "**Retrieving Relevant Documents**\n",
        "\n",
        "Write code that performs the Retrieval stage in the RAG pipeline.\n",
        "\n",
        " define a sample user query to test the RAG pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "XtLFEiXKc3ou"
      },
      "outputs": [],
      "source": [
        "sample_user_query = \"How to connect PowerBi to a database?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbPrX-29EwT6"
      },
      "source": [
        "Retrieve the relevant chunks from the documents based on the `user_query`.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_document_chunks = retriever.invoke(sample_user_query)"
      ],
      "metadata": {
        "id": "okf9mGZNYdMa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(relevant_document_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEszX2MVEVq4",
        "outputId": "a3c8f756-c67d-42e5-ef52-b5c21b9032c8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "kXbIvKgcc-2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6c2028-1a54-4346-8dba-db6a5fc0d07a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137 C H A P T E R  4  |  Using Power BI Desktop \n",
            " \n",
            "Figure 4-3: Before importing data from an SQL \n",
            "database, you need to choose the loading method. \n",
            "Let’s take a moment to learn about this \n",
            "connection option because it is an important \n",
            "one and will help shed more light on how Power \n",
            "BI connections work. \n",
            "When you choose Import, Power BI Desktop \n",
            "connects to the database, loads the information, \n",
            "and stores it within its internal data model. You \n",
            "can then work on your data in Power BI Desktop \n",
            "without being connected to the database. You \n",
            "will only need a connection when you want to \n",
            "refresh the data. \n",
            "With DirectQuery, Power BI Desktop does not \n",
            "load the data into its internal database. Instead, \n",
            "it runs a query to the original database every \n",
            "time it needs to draw a chart or, in general, run a \n",
            "query. Thus, the connection between Power BI \n",
            "Desktop and the database will be permanent. \n",
            "The contrast in the query timings reflects a key \n",
            "difference: when you use Import, you are \n",
            "working with data that is only as current as the \n",
            "latest refresh, whereas with DirectQuery you \n",
            "always see the latest information available when \n",
            "you create the report.\n"
          ]
        }
      ],
      "source": [
        "# Inspecting the first document\n",
        "for document in relevant_document_chunks:\n",
        "    print(document.page_content.replace(\"\\t\", \" \"))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5RgCKaScahT"
      },
      "source": [
        "## Generation Stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1EpXcixFL1v"
      },
      "source": [
        "This section will perform the **Generation** stage of the RAG pipeline.\n",
        "\n",
        "We will pass the relevant context chunks to the LLM, along with the system message and user message via a prompt template.\n",
        "\n",
        "These are then passed to the LLM to compose an appropriate response to the user's query.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgPj8vtcbQp"
      },
      "source": [
        "### Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxvNsmoNIbA3"
      },
      "source": [
        "Define the system message for the RAG chatbot with the appopriate role, context and the relevant instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hbhiaR6qcu9_"
      },
      "outputs": [],
      "source": [
        "qna_system_message = \"\"\"\n",
        "You are an assistant to analytics team who answers user queries on PowerBi.\n",
        "User input will have the context required by you to answer user queries.\n",
        "This context will be delimited by:\n",
        "<Context> and </Context>.\n",
        "The context contains references to specific portions of a document relevant to the user query.\n",
        "User queries will be delimited by:\n",
        "<Question> and </Question>.\n",
        "Please answer user queries only using the context provided in the input.\n",
        "Do not mention anything about the context in your final answer. Your response should only contain the answer to the question.\n",
        "If the answer is not found in the context, respond \"I don't know\".\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnyIL8-RIiyP"
      },
      "source": [
        "Write the user message prompt template that provides the relevant chunks and the user query within the `context` and `question` placeholders respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0DGOFaltczH1"
      },
      "outputs": [],
      "source": [
        "qna_user_message_template = \"\"\"\n",
        "<Context>\n",
        "Here are some documents that are relevant to the question mentioned below.\n",
        "{context}\n",
        "</Context>\n",
        "\n",
        "<Question>\n",
        "{question}\n",
        "</Question>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEPtQC14IZJj"
      },
      "source": [
        "### Generating the Response\n",
        "In this step, you need to:   \n",
        "\n",
        "Prompt construction, LLM API call with error handling, and response parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "66KLQAE5dH3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a10e07f-a09a-4812-d896-09b4b3049f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To configure automatic refresh in Power BI, you need to expand the Schedule Refresh section after setting the credentials for your data source. This allows you to define when Power BI attempts to refresh the dataset. You can schedule the refresh to run daily or weekly at different times. Note that a Power BI Pro license is required to schedule more than one refresh per day; with a free license, you can only schedule one daily refresh.\n"
          ]
        }
      ],
      "source": [
        "user_query = \"How to configure automatic refresh in PowerBI?\"\n",
        "\n",
        "relevant_document_chunks = retriever.invoke(user_query)\n",
        "context_list = [d.page_content for d in relevant_document_chunks]\n",
        "context_for_query = \"\\n---\\n\".join(context_list)\n",
        "\n",
        "prompt = [\n",
        "    {'role': 'system', 'content': qna_system_message},\n",
        "    {'role': 'user', 'content': qna_user_message_template.format(\n",
        "         context=context_for_query,\n",
        "         question=user_query\n",
        "        )\n",
        "    }\n",
        "]\n",
        "\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=prompt,\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    prediction = response.choices[0].message.content.strip()\n",
        "except Exception as e:\n",
        "    prediction = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation\n",
        "\n",
        "*  If we give strict prompt with context and questions, it only answers from the context. And if the answer is not found in the context, it responds \"I don't know\" as given.\n",
        "*   It helps in reducing hallucination risk.\n",
        "*   Gives facts based answers only. (basically only from the uploaded document)"
      ],
      "metadata": {
        "id": "028Vi0kCrDhA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTZ3kbxBcYX7"
      },
      "source": [
        "# Putting it all together - PowerBI RAG Q&A Chatbot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIF7IW1SHlkL"
      },
      "source": [
        "We'll now put together the relevant codes for the RAG pipeline into a file named `rag-chat.py` to create a basic command-line chat interface which can run via  the terminal.\n",
        "\n",
        "This naive RAG implementation illustrates how document Q&A could be automated for any domain.\n",
        "\n",
        "Write code that use the `%%writefile` magic command specific to Google Colab, which allows the content of a cell to be written directly into a file on the virtual machine's disk.\n",
        "\n",
        "This allows for the creation of scripts, configuration files, or data files within the Colab environment. These files are available during the Colab runtime and are deleted when the runtime is stopped or deleted.\n",
        "\n",
        "The `!python` shell command can be used to execute a Python script (.py files) or commands within the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8Yt6WcJSdhEa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Set the OpenAI API key as an environment variable.\n",
        "# This allows libraries (like the OpenAI SDK) to automatically detect the key without hardcoding it in the script.\n",
        "os.environ['openai_api_key'] = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1ZrGg7Uwdlph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7edc484d-d11b-425f-d643-88c36e0e5ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rag-chat.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile rag-chat.py\n",
        "import os\n",
        "import chromadb\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "import logging\n",
        "logging.getLogger(\"chromadb\").setLevel(logging.CRITICAL)\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "model_name = 'gpt-4o-mini'\n",
        "collection_name = 'powerbi_docs'\n",
        "openai_api_key = os.environ.get('openai_api_key')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=\"openai_base_url\"\n",
        ")\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    api_key=openai_api_key,\n",
        "    base_url=\"openai_base_url\",\n",
        "    model='text-embedding-3-small'\n",
        ")\n",
        "\n",
        "chromadb_client = chromadb.PersistentClient(\n",
        "    path=\"./powerbi_docs\"\n",
        ")\n",
        "\n",
        "vectorstore_persisted = Chroma(\n",
        "    collection_name=collection_name,\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "    embedding_function=embedding_model,\n",
        "    client=chromadb_client,\n",
        "    persist_directory=\"./powerbi_docs\"\n",
        ")\n",
        "\n",
        "retriever = vectorstore_persisted.as_retriever(\n",
        "    search_type='similarity',\n",
        "    search_kwargs={'k': 5}\n",
        ")\n",
        "\n",
        "qna_system_message = \"\"\"\n",
        "You are an assistant to analytics team who answers user queries on PowerBi.\n",
        "User input will have the context required by you to answer user queries.\n",
        "This context will be delimited by:\n",
        "<Context> and </Context>.\n",
        "The context contains references to specific portions of a document relevant to the user query.\n",
        "User queries will be delimited by:\n",
        "<Question> and </Question>.\n",
        "Please answer user queries only using the context provided in the input.\n",
        "Do not mention anything about the context in your final answer. Your response should only contain the answer to the question.\n",
        "If the answer is not found in the context, respond \"I don't know\".\n",
        "\"\"\"\n",
        "\n",
        "qna_user_message_template = \"\"\"\n",
        "<Context>\n",
        "Here are some documents that are relevant to the question mentioned below.\n",
        "{context}\n",
        "</Context>\n",
        "\n",
        "<Question>\n",
        "{question}\n",
        "</Question>\n",
        "\"\"\"\n",
        "\n",
        "def respond(user_query):\n",
        "    relevant_document_chunks = retriever.invoke(user_query)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "    context_for_query = \"\\n---\\n\".join(context_list)\n",
        "\n",
        "    prompt = [\n",
        "        {'role': 'system', 'content': qna_system_message},\n",
        "        {\n",
        "            'role': 'user', 'content': qna_user_message_template.format(\n",
        "             context=context_for_query,\n",
        "             question=user_query)\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=prompt,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        answer = response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        answer = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "    return answer\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Runs the main interactive loop for the Q&A system.\n",
        "\n",
        "    This function initializes the conversation history, continuously prompts\n",
        "    the user for queries, processes the queries using the `respond` function,\n",
        "    and displays the assistant's responses. It also maintains the\n",
        "    conversation history for context.\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Initialize conversation history.\n",
        "    # This list stores the conversation between the user and the assistant.\n",
        "    # It starts with a system message introducing the assistant's role.\n",
        "    conversation_history = [\n",
        "        {'role': 'system', 'content': 'You are a assistant who answers user queries on PowerBi'}\n",
        "\n",
        "        ]\n",
        "\n",
        "    # 2. Enter the interactive loop.\n",
        "    # The loop continues until the user enters 'q' to quit.\n",
        "    while True:\n",
        "        # 2.1 Get user input.\n",
        "        # Prompt the user to enter a query and store it in `user_query`.\n",
        "        user_query = input(\"User (type q to quit): \")\n",
        "\n",
        "        # 2.2 Check for quit condition.\n",
        "        # If the user enters 'q', break out of the loop.\n",
        "        if user_query == 'q':\n",
        "            break\n",
        "\n",
        "        # 2.3 Process the query and get the answer.\n",
        "        # Call the `respond` function to process the user query and get the answer.\n",
        "        answer = respond(user_query)\n",
        "\n",
        "        # 2.4 Update conversation history.\n",
        "        # Add the user's query and the assistant's answer to the conversation history.\n",
        "        conversation_history.append({'role': 'user', 'content': user_query})\n",
        "        conversation_history.append({'role': 'assistant', 'content': answer})\n",
        "\n",
        "        # 2.5 Display the assistant's answer.\n",
        "        # Print the assistant's answer to the console.\n",
        "        print(f\"Assistant: {answer}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fomulate 5 queries on the PowerBI Documentation that will then be used to validate the the Q&A RAG Chatbot and provide the output responses."
      ],
      "metadata": {
        "id": "fyFkjk_d6CVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. How to share PowerBi dashboard to a group?\n",
        "2. How to use Query Editor?\n",
        "3. What is DAX?\n",
        "4. Is Data refresh and live connection mean the same in PowerBi?\n",
        "5. How to choose visuals in PowerBi?"
      ],
      "metadata": {
        "id": "gYoATYZ83xZm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWIxtiuyH5Jv"
      },
      "source": [
        "Run the script using the `!python` shell command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ayp5qZt6dvDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0797ce-367e-45c2-fcb2-5afb1d21e349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User (type q to quit): How to share PowerBi dashboard to a group?\n",
            "Assistant: To share a Power BI dashboard with a group, you need to create a group of users in Power BI. Once the group is created, you can automatically share all of your dashboards with that group. However, you must have a Power BI Pro license to access the group feature, as it is not available in the free version. After creating the group, you can invite users to join and provide editing rights to certain users within that group.\n",
            "User (type q to quit): How to use Query Editor?\n",
            "Assistant: To use Query Editor in Power BI Desktop, you can follow these steps:\n",
            "\n",
            "1. Open Power BI Desktop and access the Query Editor by clicking on \"Edit Queries\" in the Home tab of the ribbon.\n",
            "2. The Query Editor window will open, displaying various options. The top of the window features a ribbon with four tabs: Home, Transform, Add Column, and View.\n",
            "3. On the left side, you will see the Query pane, which lists all the queries for your model. The middle pane shows the result of the selected query, and the Query Settings pane on the right displays the properties of the query.\n",
            "4. You can modify queries, delete columns, and change data types as needed. For example, to change a custom column's data type to Decimal Number, select the column and define its data type.\n",
            "5. You can also create new tables by clicking on \"Enter Data\" in the New Query group, allowing you to type or paste data into a grid.\n",
            "6. To join tables, select the query you want to modify and use the \"Merge Queries\" option in the Home tab.\n",
            "\n",
            "These steps will help you navigate and utilize the features of Query Editor effectively.\n",
            "User (type q to quit): What is DAX?\n",
            "Assistant: DAX, which stands for Data Analysis Expressions, is a language used in Power BI for creating calculations and data analysis. It was introduced in Power Pivot for Excel in 2010 and is based on the Excel formula language. DAX includes many functions that have the same name and syntax as those in Excel, but it also has several new concepts and functions.\n",
            "User (type q to quit): Is Data refresh and live connection mean the same in PowerBi? How to choose visuals in PowerBi?\n",
            "Assistant: Data refresh and live connection do not mean the same in Power BI. Data refresh involves updating the data in Power BI, while a live connection sends real-time queries to the data source without creating a copy of the data. When using a live connection, your Power BI model can have only one data source, and a single report cannot mix visualizations from different data sources. To combine visualizations from different sources, you must import data into Power BI.\n",
            "User (type q to quit): How to choose visuals in PowerBi?\n",
            "Assistant: You have several standard visualizations available in Power BI, and you can extend this set by using custom visualizations. Before doing that, you need to know what you can and cannot do using the standard components. It's also encouraged to experiment by using different visualizations for better understanding and insights. Additionally, you can manage visualization details such as titles and font sizes to enhance clarity.\n",
            "User (type q to quit): q\n"
          ]
        }
      ],
      "source": [
        "!python rag-chat.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html \"/content/drive/My Drive/Colab_Notebooks/Sukanyaa_Sundaram_Project_1_RAG_Gen_AI_for_Practitioners(Full_Code).ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX3J6v3XBCBa",
        "outputId": "4649caf4-fd4e-4688-f419-82bb73d20896"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/My Drive/Colab_Notebooks/Sukanyaa_Sundaram_Project_1_RAG_Gen_AI_for_Practitioners(Full_Code).ipynb to html\n",
            "[NbConvertApp] WARNING | Alternative text is missing on 1 image(s).\n",
            "[NbConvertApp] Writing 393492 bytes to /content/drive/My Drive/Colab_Notebooks/Sukanyaa_Sundaram_Project_1_RAG_Gen_AI_for_Practitioners(Full_Code).html\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}